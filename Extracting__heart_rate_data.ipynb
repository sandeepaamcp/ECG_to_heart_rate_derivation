{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting _heart_rate_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeepaamcp/ECG_to_heart_rate_derivation/blob/dev/Extracting__heart_rate_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq2vS43Qiuoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install wfdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2LHkOdniz54",
        "colab_type": "code",
        "outputId": "ecc699eb-1dd2-413f-b47e-47793e1125e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "import numpy as np\n",
        "import linecache\n",
        "import os, fnmatch\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrgvP0kxrray",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_data(output_x_file_path, output_y_file_path, patient_data_file_path, heart_rate_values): \n",
        "  output_x_file= open(output_x_file_path,\"w+\")\n",
        "  for index,value in np.ndenumerate(heart_rate_values):\n",
        "    output_x_file.write(\"%.3f\\n\" % value)\n",
        "    \n",
        "  output_x_file.close() \n",
        "\n",
        "  patient_summary_file_path=patient_data_file_path + \".hea\"\n",
        "\n",
        "  lookup = 'Reason for admission:'\n",
        "  linenum = 0\n",
        "  with open(patient_summary_file_path) as f:\n",
        "  # #with open('/content/drive/My Drive/HR_data/patient1/s0010_re.hea') as f:\n",
        "      for num, line in enumerate(f, 1):\n",
        "          if lookup in line:\n",
        "              #print ('found at line:', num)\n",
        "              linenum=num\n",
        "              \n",
        "  reason_for_admission=linecache.getline(patient_summary_file_path, linenum).rstrip()\n",
        "  #y_str=linecache.getline('/content/drive/My Drive/HR_data/patient1/s0010_re.hea', linenum).rstrip()\n",
        "  #y_str\n",
        "\n",
        "  reason_for_admission = reason_for_admission.split(\": \",1)[1]\n",
        "  #print(reason_for_admission)\n",
        "\n",
        "  categories = [\"Myocardial infarction\", \"Cardiomyopathy\", \"Bundle branch block\", \"Dysrhythmia\",\n",
        "                \"Myocardial hypertrophy\", \"Valvular heart disease\", \"Myocarditis\", \"Miscellaneous\",\n",
        "                \"Healthy controls\"]\n",
        "\n",
        "\n",
        "  output_y_file = open(output_y_file_path,\"w+\")\n",
        "\n",
        "  for idx, diseases in enumerate(categories):\n",
        "    if reason_for_admission in diseases:\n",
        "      # print(idx)\n",
        "      output_y_file.write(\"%d\\n\" % idx)\n",
        "      break  \n",
        "    elif len(categories)-1 == idx:\n",
        "      #print(\"ERROR. Reason for admission is not given in patient summary\")\n",
        "      # print(-1)\n",
        "      output_y_file.write(\"%d\\n\" % idx)\n",
        "  output_y_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOTqXAQVLhQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def derive_heart_rate_from_ECG(ECG_input_data_file_path):\n",
        "  record = wfdb.rdrecord(ECG_input_data_file_path, sampfrom=0, channels=[0])\n",
        "\n",
        "  # Use the gqrs algorithm to detect qrs locations in the first channel\n",
        "  qrs_inds = processing.gqrs_detect(sig=record.p_signal[:,0], fs=record.fs)\n",
        "\n",
        "  # Correct the peaks shifting them to local maxima\n",
        "  min_bpm = 20\n",
        "  max_bpm = 230\n",
        "  #min_gap = record.fs * 60 / min_bpm\n",
        "  # Use the maximum possible bpm as the search radius\n",
        "  search_radius = int(record.fs * 60 / max_bpm)\n",
        "  corrected_peak_inds = processing.correct_peaks(record.p_signal[:,0], peak_inds=qrs_inds,\n",
        "                                                search_radius=search_radius, smooth_window_size=150)\n",
        "\n",
        "\n",
        "  hrs = processing.compute_hr(sig_len=record.p_signal.shape[0], qrs_inds=sorted(corrected_peak_inds), fs=record.fs)\n",
        "\n",
        "  #print(hrs.size)\n",
        "  heart_rate_raw = np.array([x for x in hrs if str(x) != 'nan'])\n",
        "  # heartRate = hrs\n",
        "  # print(heart_rate_raw)\n",
        "\n",
        "  heart_rate_values = np.zeros(int(heart_rate_raw.shape[0]/1000)+1)\n",
        "  #print(heart_rate_values.size)\n",
        "  i = 0\n",
        "  j = 0\n",
        "\n",
        "  while i<heart_rate_raw.size:\n",
        "    if i%1000==0:\n",
        "      heart_rate_values[j]= heart_rate_raw[i]\n",
        "      j+=1\n",
        "    i+=1\n",
        "  return heart_rate_values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgrJDzvjZW6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SERIAL LOOP\n",
        "start_time = time.time()\n",
        "\n",
        "counter = 0\n",
        "k = 10\n",
        "while k < 12:\n",
        "  print(k)\n",
        "  # Load the wfdb record and the physical samples\n",
        "  if k < 10:\n",
        "    input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient00{}'\n",
        "  elif k < 100:\n",
        "    input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient0{}'\n",
        "  else:\n",
        "    input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient{}'\n",
        "\n",
        "  hea_files = fnmatch.filter(os.listdir(input_data_file_path.format(k)), '*re.hea')\n",
        "  #print(hea_files)\n",
        "  for i in hea_files:\n",
        "    #print(i.split(\".\")[0])\n",
        "    data_file_path = input_data_file_path.format(k) + \"/\" + i.split(\".\")[0]\n",
        "    heart_rate_values = derive_heart_rate_from_ECG(data_file_path)\n",
        "    output_x_file_path=r\"/content/drive/My Drive/datasets/test_results/x/\"+str(counter)+\".txt\".format(k,i)\n",
        "    output_y_file_path = r\"/content/drive/My Drive/datasets/test_results/y/\"+str(counter)+\".txt\".format(k,i)\n",
        "    write_data(output_x_file_path, output_y_file_path, data_file_path, heart_rate_values )\n",
        "    counter = counter + 1\n",
        "  k+=1\n",
        "\n",
        "elapsed_time_serial = time.time() - start_time\n",
        "print(\"Elapsed Time:\",elapsed_time_serial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISai5gTcwC8N",
        "colab_type": "text"
      },
      "source": [
        "Atomic Counter for Python\n",
        "\n",
        "References:\n",
        "\n",
        "https://gist.github.com/benhoyt/8c8a8d62debe8e5aa5340373f9c509c7\n",
        "\n",
        "https://eli.thegreenplace.net/2012/01/04/shared-counter-with-pythons-multiprocessing\n",
        "\n",
        "This Code:\n",
        "\n",
        "https://stackoverflow.com/questions/2080660/python-multiprocessing-and-a-shared-counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cqs3FUVv8dC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "961cdf9c-2b02-44c1-e978-5a23e6dc77e9"
      },
      "source": [
        "#PARALLEL IMPLEMENTATION START\n",
        "import threading\n",
        "\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "\n",
        "print(multiprocessing.cpu_count())\n",
        "\n",
        "class AtomicCounter:\n",
        "    def __init__(self, initval=0):\n",
        "        self.val = multiprocessing.RawValue('i', initval)\n",
        "        self.lock = multiprocessing.Lock()\n",
        "\n",
        "    def increment(self):\n",
        "        with self.lock:\n",
        "            self.val.value += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.val.value"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tETVw0P90zIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NEED AN ATOMIC COUNTER TO INCREMENT\n",
        "file_id_value = AtomicCounter(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8eVBmQLoHGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main_loop(data_file_path):\n",
        "  global file_id_value\n",
        "  heart_rate_values = derive_heart_rate_from_ECG(data_file_path)\n",
        "  print(data_file_path)\n",
        "  # print(\"file id:\")\n",
        "  # file_id.increment()\n",
        "  # print(file_id.value)\n",
        "  file_id_val = file_id_value.increment()\n",
        "  # print(file_id_val)\n",
        "  output_x_file_path=r\"/content/drive/My Drive/datasets/test_results/x/\"+str(file_id_value.value)+\".txt\"\n",
        "  output_y_file_path = r\"/content/drive/My Drive/datasets/test_results/y/\"+str(file_id_value.value)+\".txt\"\n",
        "  write_data(output_x_file_path, output_y_file_path, data_file_path, heart_rate_values )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g84LiLTqdb_J",
        "colab_type": "code",
        "outputId": "ee28a2d7-960d-4de9-a869-4dbc3702a52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "start_time = time.time()\n",
        "counter = 0\n",
        "k = 10\n",
        "end = 12\n",
        "file_paths = []\n",
        "\n",
        "while k < end:\n",
        "  # Load the wfdb record and the physical samples\n",
        "  if k < 10:\n",
        "    input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient00{}'\n",
        "  elif k < 100:\n",
        "    input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient0{}'\n",
        "  else:\n",
        "    input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient{}'\n",
        "  try:\n",
        "    hea_files = fnmatch.filter(os.listdir(input_data_file_path.format(k)), '*re.hea')\n",
        "    for i in hea_files:\n",
        "      data_file_path = input_data_file_path.format(k) + \"/\" + i.split(\".\")[0]\n",
        "      file_paths.append(data_file_path)\n",
        "      counter = counter + 1\n",
        "    k+=1\n",
        "  except OSError as e:\n",
        "    print(e)\n",
        "    counter = counter + 1\n",
        "    k+=1\n",
        "\n",
        "pool = Pool(multiprocessing.cpu_count()) # Create a multiprocessing Pool\n",
        "pool.map(main_loop,file_paths)  # process data_inputs iterable with pool\n",
        "\n",
        "elapsed_time_parallel = time.time() - start_time\n",
        "print(\"Elapsed Time: \",elapsed_time_parallel)\n",
        "# print(\"speedup: \", str(elapsed_time_serial/elapsed_time_parallel))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/datasets/HR_data/patient010/s0042lre\n",
            "/content/drive/My Drive/datasets/HR_data/patient010/s0061lre\n",
            "/content/drive/My Drive/datasets/HR_data/patient011/s0044lre\n",
            "/content/drive/My Drive/datasets/HR_data/patient011/s0049lre\n",
            "/content/drive/My Drive/datasets/HR_data/patient011/s0067lre\n",
            "Elapsed Time:  7.418703079223633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiMThRiHsMS_",
        "colab_type": "text"
      },
      "source": [
        "The speedup was almost the same, which signifies the issue of I/O bound.\n",
        "\n",
        "REFERENCES:\n",
        "\n",
        "https://en.wikipedia.org/wiki/I/O_bound \n",
        "\n",
        "https://stackoverflow.com/questions/42620323/why-is-reading-multiple-files-at-the-same-time-slower-than-reading-sequentially\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuA2NRj_byoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ATTEMPT 02:\n",
        "#FILE READ BY ONE THREAD, DATA EXTRACTION BY ANOTHER THREAD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9AzS8_ti8iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tempfile, shutil, os\n",
        "# def create_temporary_copy(path,new_name):\n",
        "#     temp_dir = tempfile.gettempdir()\n",
        "#     temp_path = os.path.join(temp_dir, new_name)\n",
        "#     shutil.copy2(path, temp_path)\n",
        "#     return temp_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiSNgB_MWgck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# contents_all = []\n",
        "# i = 0\n",
        "# for file_path in file_paths:\n",
        "#   # contents_all.append(create_temporary_copy(file_path+\".dat\",str(i)))\n",
        "#   contents_all.append(create_temporary_copy(\"/content/drive/My Drive/datasets/HR_data/patient011\",str(i)))\n",
        "#   i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh7OPSXz4eC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# contents_all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g2xD-2X4foN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('/tmp/0', 'rb') as f:\n",
        "#     file_contents=f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djPN81Mc5SAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start_time = time.time()\n",
        "# counter = 0\n",
        "# k = 10\n",
        "# end = 15\n",
        "# file_paths = []\n",
        "# folder_paths = []\n",
        "# while k < end:\n",
        "#   # Load the wfdb record and the physical samples\n",
        "#   if k < 10:\n",
        "#     input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient00{}'\n",
        "#   elif k < 100:\n",
        "#     input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient0{}'\n",
        "#   else:\n",
        "#     input_data_file_path = r'/content/drive/My Drive/datasets/HR_data/patient{}'\n",
        "#   folder_paths.append(input_data_file_path)\n",
        "#   hea_files = fnmatch.filter(os.listdir(input_data_file_path.format(k)), '*re.hea')\n",
        "#   for i in hea_files:\n",
        "#     data_file_path = input_data_file_path.format(k) + \"/\" + i.split(\".\")[0]\n",
        "#     file_paths.append(data_file_path)\n",
        "#     counter = counter + 1\n",
        "#   k+=1\n",
        "\n",
        "# pool = Pool(multiprocessing.cpu_count()) # Create a multiprocessing Pool\n",
        "# pool.map(main_loop,file_paths)  # process data_inputs iterable with pool\n",
        "\n",
        "# elapsed_time_parallel = time.time() - start_time\n",
        "# print(\"Elapsed Time: \",elapsed_time_parallel)\n",
        "# print(\"speedup: \", str(elapsed_time_serial/elapsed_time_parallel))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6p8sN4D8fIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}